apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: execute-ai-analysis
spec:
  description: >-
    Complete SAST AI workflow that prepares source, fetches false positives,
    runs AI analysis, uploads results to Google Drive, and cleans up resources.
    Uses emptyDir volumes for efficient resource management.
  params:
    # Parameters from prepare-source
    - name: REPO_REMOTE_URL
      type: string
      description: Source code URL (SRPM or Git repo)
    
    # Parameters from fetch-false-positives  
    - name: FALSE_POSITIVES_URL
      type: string
      description: "Optional GitLab URL containing known false positives"
      default: ""
    
    # Parameters from execute-ai-analysis
    - name: PROJECT_NAME
      type: string
      default: ""
    - name: PROJECT_VERSION
      type: string
      default: ""
    - name: INPUT_REPORT_FILE_PATH
      type: string
      default: ""
    - name: HUMAN_VERIFIED_FILE_PATH
      type: string
      description: "Path to human verified file for validation"
      default: ""
    - name: AGGREGATE_RESULTS_G_SHEET
      type: string
      default: ""
    - name: LLM_URL
      type: string
      default: ""
    - name: LLM_MODEL_NAME
      type: string
      default: ""
    - name: LLM_API_TYPE
      type: string
      default: "nim"
    - name: EMBEDDINGS_LLM_URL
      type: string
      default: ""
    - name: EMBEDDINGS_LLM_MODEL_NAME
      type: string
      default: ""
    - name: USE_KNOWN_FALSE_POSITIVE_FILE
      type: string
      description: "Whether to use known false positive file for filtering (true/false)"
      default: "true"
    - name: GIT_COMMIT_HASH
      type: string
      description: "Git commit hash from prepare-source task"
      default: ""
    - name: GIT_BRANCH
      type: string
      description: "Git branch from prepare-source task"
      default: ""
    - name: REPO_URL
      type: string
      description: "Source repository URL"
      default: ""
    - name: GDRIVE_FOLDER_ID
      type: string
      description: "Google Drive folder ID for uploading SAST results (optional)"
      default: ""
    - name: GDRIVE_SA_FILE_NAME
      type: string
      description: "Optional GDrive SA file name"
      default: "service_account.json"
    - name: CONTAINER_IMAGE
      type: string
      description: "Container image to use for SAST AI analysis"
      default: "quay.io/ecosystem-appeng/sast-ai-workflow:latest"
    - name: BASE_IMAGE
      type: string
      description: "Base image with pre-installed dependencies"
      default: "quay.io/ecosystem-appeng/sast-ai-base-image:latest"

    - name: GCS_BUCKET_NAME
      type: string
      description: "GCS bucket name for uploading SARIF reports (optional)"
      default: ""
    - name: GCS_SA_FILE_NAME
      type: string
      description: "GCS service account file name (constant)"
      default: "gcs_service_account.json"

  workspaces:
    - name: gitlab-token-ws
      description: "Optional secret mount for GitLab token (if needed)"
      optional: true
    - name: google-sa-json-ws
      description: "Secret mount for Google Drive service account"
    - name: gcs-sa-json-ws
      description: "Optional secret mount for GCS service account"
      optional: true

  volumes:
    - name: shared-data
      emptyDir:
        sizeLimit: "10Gi"
    - name: cache-data
      emptyDir:
        sizeLimit: "5Gi"
    - name: gdrive-scripts
      configMap:
        name: sast-ai-gdrive-upload-scripts
        defaultMode: 0755
    - name: gcs-scripts
      configMap:
        name: sast-ai-gcs-upload-scripts
        defaultMode: 0755
  results:
    - name: repo-local-path
      description: "Local path to the prepared source code directory"
    - name: report-file-path
      description: "Final path to the report file (converted to SARIF if needed)"
    - name: dvc-data-version
      description: "Generated DVC data version tag for this execution"
    - name: dvc-commit-hash
      description: "Git commit hash for DVC metadata"
    - name: dvc-pipeline-stage
      description: "DVC pipeline stage identifier"

  steps:
    # STEP 1: Validate Input URLs
    - name: validate-input-urls
      image: $(params.BASE_IMAGE)
      env:
        - name: REPO_REMOTE_URL
          value: "$(params.REPO_REMOTE_URL)"
        - name: FALSE_POSITIVES_URL
          value: "$(params.FALSE_POSITIVES_URL)"
      command: ["/scripts/validate_input_urls.sh"]

    # STEP 2: Validate Report File
    - name: validate-report-file
      image: $(params.BASE_IMAGE)
      env:
        - name: INPUT_REPORT_FILE_PATH
          value: "$(params.INPUT_REPORT_FILE_PATH)"
        - name: GOOGLE_SA_JSON_PATH
          value: "$(workspaces.google-sa-json-ws.path)/service_account.json"
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
      command: ["/scripts/validate_report_file.sh"]

    # STEP 3: Prepare Source Code
    - name: prepare-source
      image: $(params.BASE_IMAGE)
      securityContext:
        runAsUser: 0
      env:
        - name: HOME
          value: "/shared-data"
        - name: SRC_URL
          value: "$(params.REPO_REMOTE_URL)"
        - name: WORKDIR
          value: "/shared-data"
        - name: TEKTON_RESULTS_DIR
          value: "$(results.repo-local-path.path)"
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
      command: ["/scripts/prepare_source.sh"]

    # STEP 4: Transform SAST Report to SARIF Format
    - name: transform-report
      image: $(params.BASE_IMAGE)
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
      env:
        - name: INPUT_REPORT_FILE_PATH
          value: "$(params.INPUT_REPORT_FILE_PATH)"
        - name: TEKTON_RESULTS_DIR
          value: "$(results.report-file-path.path)"
      command: ["/scripts/transform_report.sh"]

    # STEP 5: Fetch False Positives
    - name: fetch-false-positives
      image: $(params.BASE_IMAGE)
      env:
        - name: FP_URL
          value: "$(params.FALSE_POSITIVES_URL)"
        - name: USE_KNOWN_FALSE_POSITIVE_FILE
          value: "$(params.USE_KNOWN_FALSE_POSITIVE_FILE)"
        - name: GITLAB_TOKEN_PATH
          value: "$(workspaces.gitlab-token-ws.path)/gitlab_token"
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
      command: ["/scripts/fetch_false_positives.sh"]

    # STEP 6: Execute SAST AI Analysis
    - name: run-analysis
      image: $(params.CONTAINER_IMAGE)
      env:
        - name: PROJECT_NAME
          value: "$(params.PROJECT_NAME)"
        - name: PROJECT_VERSION
          value: "$(params.PROJECT_VERSION)"
        - name: KNOWN_FALSE_POSITIVE_FILE_PATH
          value: "/shared-data/false-positives/ignore.err"
        - name: USE_KNOWN_FALSE_POSITIVE_FILE
          value: "$(params.USE_KNOWN_FALSE_POSITIVE_FILE)"
        - name: INPUT_REPORT_FILE_PATH
          value: "$(params.INPUT_REPORT_FILE_PATH)"
        - name: HUMAN_VERIFIED_FILE_PATH
          value: "$(params.HUMAN_VERIFIED_FILE_PATH)"
        - name: AGGREGATE_RESULTS_G_SHEET
          value: "$(params.AGGREGATE_RESULTS_G_SHEET)"
        - name: LLM_URL
          value: "$(params.LLM_URL)"
        - name: LLM_MODEL_NAME
          value: "$(params.LLM_MODEL_NAME)"
        - name: EMBEDDINGS_LLM_URL
          value: "$(params.EMBEDDINGS_LLM_URL)"
        - name: EMBEDDINGS_LLM_MODEL_NAME
          value: "$(params.EMBEDDINGS_LLM_MODEL_NAME)"
        - name: LLM_API_TYPE
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: llm_api_type
        - name: LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: llm_api_key
        - name: EMBEDDINGS_LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: embeddings_llm_api_key
        - name: LLM_MODEL_NAME
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: llm_model_name
        - name: EMBEDDINGS_LLM_MODEL_NAME
          valueFrom:
            secretKeyRef:
              name: sast-ai-default-llm-creds
              key: embedding_llm_model_name
        - name: SERVICE_ACCOUNT_JSON_PATH
          value: "$(workspaces.google-sa-json-ws.path)/service_account.json"
        - name: ANALYSIS_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: analysis_system_prompt
        - name: ANALYSIS_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: analysis_human_prompt
        - name: FILTER_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: filter_system_prompt
        - name: FILTER_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: filter_human_prompt
        - name: RECOMMENDATIONS_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: recommendations_prompt
        - name: JUSTIFICATION_SUMMARY_SYSTEM_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: justification_summary_system_prompt
        - name: JUSTIFICATION_SUMMARY_HUMAN_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: justification_summary_human_prompt
        - name: EVALUATION_PROMPT
          valueFrom:
            configMapKeyRef:
              name: sast-ai-prompt-templates
              key: evaluation_prompt
        - name: TMPDIR
          value: "/cache-data/tmp"
        - name: OUTPUT_FILE_PATH
          value: "/shared-data/output/sast_ai_output.xlsx"
        - name: LIBCLANG_PATH
          value: "/usr/lib64/libclang.so.20.1"
        - name: DVC_GIT_COMMIT_HASH
          value: "$(params.GIT_COMMIT_HASH)"
        - name: DVC_REPO_BRANCH
          value: "$(params.GIT_BRANCH)"
        - name: DVC_REPO_URL
          value: "$(params.REPO_URL)"
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
        - name: cache-data
          mountPath: /cache-data
      computeResources:
        requests:
          ephemeral-storage: "1Gi"
        limits:
          ephemeral-storage: "2Gi"
      script: |
        #!/usr/bin/env sh
        set -ex
        echo "=== STEP 6: RUN SAST AI ANALYSIS ==="
        
        # Load the repo path from step 4
        if [ -f "/shared-data/env.txt" ]; then
          source /shared-data/env.txt
          export REPO_LOCAL_PATH
        else
          echo "Error: No environment file found from prepare-source step" >&2
          exit 1
        fi
        
        # Use the transformed report file path if available
        if [ -f "/shared-data/report-file-path.txt" ]; then
          TRANSFORMED_REPORT_PATH=$(cat /shared-data/report-file-path.txt)
          export INPUT_REPORT_FILE_PATH="$TRANSFORMED_REPORT_PATH"
          echo "Using transformed report file path: $INPUT_REPORT_FILE_PATH"
        else
          echo "Using original report file path: $INPUT_REPORT_FILE_PATH"
        fi
        
        # Create directories
        mkdir -p "/cache-data/tmp" "/shared-data/output"
        
        echo "Running SAST-AI-Workflow with aiq..."
        aiq run --config_file /app/src/sast_agent_workflow/configs/config.yml --input "sast_agent"
        
        # Verify output file was created
        if [ -f "/shared-data/output/sast_ai_output.xlsx" ]; then
          echo "Analysis completed successfully"
        else
          echo "Error: Output file not found!" >&2
          exit 1
        fi

    # STEP 7: Upload to Google Drive
    - name: upload-to-gdrive
      image: $(params.BASE_IMAGE)
      env:
        - name: GDRIVE_FOLDER_ID
          value: "$(params.GDRIVE_FOLDER_ID)"
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: "$(workspaces.google-sa-json-ws.path)/$(params.GDRIVE_SA_FILE_NAME)"
        - name: PROJECT_NAME
          value: "$(params.PROJECT_NAME)"
        - name: PROJECT_VERSION
          value: "$(params.PROJECT_VERSION)"
        - name: GDRIVE_FOLDER_ID_FROM_CM
          valueFrom:
            configMapKeyRef:
              name: sast-ai-gdrive-config
              key: folder-id
              optional: true
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
        - name: gdrive-scripts
          mountPath: /scripts/gdrive
      command: ["/scripts/upload_to_gdrive.sh"]

    # STEP 8: Upload SARIF to GCS Bucket
    - name: upload-sarif-to-gcs
      image: $(params.BASE_IMAGE)
      env:
        - name: GCS_BUCKET_NAME
          value: "$(params.GCS_BUCKET_NAME)"
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: "$(workspaces.gcs-sa-json-ws.path)/$(params.GCS_SA_FILE_NAME)"
        - name: PROJECT_NAME
          value: "$(params.PROJECT_NAME)"
        - name: PROJECT_VERSION
          value: "$(params.PROJECT_VERSION)"
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
        - name: gcs-scripts
          mountPath: /scripts/gcs
      command: ["/scripts/upload_sarif_to_gcs.sh"]

    # STEP 9: Cleanup (Always runs)
    - name: cleanup
      image: $(params.BASE_IMAGE)
      volumeMounts:
        - name: shared-data
          mountPath: /shared-data
        - name: cache-data
          mountPath: /cache-data
      command: ["/scripts/cleanup.sh"]
