# Evaluation Mode Patches for MLOps Overlay
#
# This file patches the base Tekton task to support evaluation mode for individual nodes.
# When "all" is NOT present in EVALUATE_SPECIFIC_NODE, the following steps are skipped:
# - Step 7: upload-to-gdrive (Google Drive upload)
# - Step 8: upload-sarif-to-gcs (GCS upload)
# - Step 9: cleanup
#
# EVALUATE_SPECIFIC_NODE can be:
# - "all" - runs normal SAST workflow + uploads/cleanup
# - "filter" - runs only filter evaluation, skips uploads/cleanup
# - "all,filter" - runs normal SAST workflow + filter evaluation + uploads/cleanup
#
# IMPORTANT: Future upload steps (e.g., S3/MinIO from PR #133) must also include this check:
#   EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
#   if ! echo ",$EVAL_NODES," | grep -q ",all,"; then
#     echo "Skipping [step name] in evaluation mode"
#     exit 0
#   fi
#
- op: add
  path: /spec/results/-
  value:
    name: evaluation-results
    description: "JSON array of evaluation results from all evaluated nodes"
- op: add
  path: /spec/results/-
  value:
    name: workflow-metrics
    description: "JSON containing workflow metrics (TP/FP/TN/FN, accuracy, precision, recall, F1)"
- op: replace
  path: /spec/steps/5/image
  value: "$(params.CONTAINER_IMAGE)"
- op: replace
  path: /spec/steps/5/script
  value: |
    #!/usr/bin/env sh
    set -ex
    echo "=== STEP 6: RUN SAST AI ANALYSIS OR EVALUATION ==="

    # Load the repo path from step 4
    if [ -f "/shared-data/env.txt" ]; then
      source /shared-data/env.txt
      export REPO_LOCAL_PATH
    else
      echo "Error: No environment file found from prepare-source step" >&2
      exit 1
    fi

    # Use the transformed report file path if available
    if [ -f "/shared-data/report-file-path.txt" ]; then
      TRANSFORMED_REPORT_PATH=$(cat /shared-data/report-file-path.txt)
      export INPUT_REPORT_FILE_PATH="$TRANSFORMED_REPORT_PATH"
      echo "Using transformed report file path: $INPUT_REPORT_FILE_PATH"
    else
      echo "Using original report file path: $INPUT_REPORT_FILE_PATH"
    fi

    # Create directories
    mkdir -p "/cache-data/tmp" "/shared-data/output"

    # Parse EVALUATE_SPECIFIC_NODE parameter
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    echo "Evaluation mode: $EVAL_NODES"

    # Check if "all" is present in the comma-separated list
    if echo ",$EVAL_NODES," | grep -q ",all,"; then
      RUN_FULL_WORKFLOW=true
    else
      RUN_FULL_WORKFLOW=false
    fi

    # Check if running normal workflow or evaluation
    if [ "$RUN_FULL_WORKFLOW" = "true" ]; then
      echo "Running normal SAST-AI-Workflow with aiq..."

      # Enable workflow metrics JSON output
      export WORKFLOW_JSON_OUTPUT="/shared-data/output/workflow_metrics.json"

      aiq run --config_file /app/src/sast_agent_workflow/configs/config.yml --input "sast_agent"

      # Verify output file was created
      if [ -f "/shared-data/output/sast_ai_output.xlsx" ]; then
        echo "Analysis completed successfully"
      else
        echo "Error: Output file not found!" >&2
        exit 1
      fi

      # Capture workflow metrics to Tekton result
      if [ -f "$WORKFLOW_JSON_OUTPUT" ]; then
        echo "Capturing workflow metrics to result..."
        cat "$WORKFLOW_JSON_OUTPUT" > $(results.workflow-metrics.path)
        echo "Workflow metrics captured successfully"
      else
        echo "No workflow metrics file found (may not have ground truth data)"
        echo "{}" > $(results.workflow-metrics.path)
      fi
    else
      echo "Running evaluation mode for nodes: $EVAL_NODES"

      # Create directory for evaluation JSON outputs
      mkdir -p /shared-data/eval_results

      # Parse comma-separated list and run each evaluation runner
      echo "$EVAL_NODES" | tr ',' '\n' | while read -r node; do
        node=$(echo "$node" | xargs)  # trim whitespace

        # Parse ground truth XLSX file if needed for this evaluation node
        if [ -f "/shared-data/report-file-path.txt" ]; then
          GROUND_TRUTH_PATH=$(cat /shared-data/report-file-path.txt)

          # Check if it's an XLSX file that needs parsing
          if [[ "$GROUND_TRUTH_PATH" =~ \.xlsx$ ]]; then
            echo "Parsing XLSX for $node evaluation..."

            # Create evaluation dataset directory
            mkdir -p /shared-data/evaluation_dataset

            # Construct package NVR
            NVR="${PROJECT_NAME}-${PROJECT_VERSION}"

            # Map node names to parser node types
            case "$node" in
              summary)
                PARSER_NODE_TYPE="summarize"
                ;;
              filter|judge)
                PARSER_NODE_TYPE="$node"
                ;;
              *)
                echo "Error: Unknown node type '$node'" >&2
                exit 1
                ;;
            esac

            # Parse XLSX to JSON using the unified parser
            python /app/evaluation/utils/parse_excel_to_json.py \
              --node-type "$PARSER_NODE_TYPE" \
              single \
              --excel-file "$GROUND_TRUTH_PATH" \
              --package-name "$NVR" \
              --output-file "/shared-data/evaluation_dataset/parsed_dataset.json"

            if [ $? -eq 0 ]; then
              echo "XLSX parsing completed successfully for $node"
              export EVALUATION_DATASET_PATH="/shared-data/evaluation_dataset/parsed_dataset.json"
            else
              echo "Error: XLSX parsing failed for $node"
              exit 1
            fi
          fi
        fi

        case "$node" in
          filter)
            echo "Running filter evaluation..."
            EVALUATION_JSON_OUTPUT=/shared-data/eval_results/filter.json \
              python /app/evaluation/runners/run_filter_evaluation.py
            ;;
          summary)
            echo "Running summary evaluation..."
            EVALUATION_JSON_OUTPUT=/shared-data/eval_results/summary.json \
              python /app/evaluation/runners/run_summarize_evaluation.py
            ;;
          judge)
            echo "Running judge LLM evaluation..."
            EVALUATION_JSON_OUTPUT=/shared-data/eval_results/judge.json \
              python /app/evaluation/runners/run_judge_llm_evaluation.py
            ;;
          *)
            echo "Warning: Unknown evaluation node '$node', skipping..."
            ;;
        esac
      done

      # Combine all JSON files into array and write to result
      echo "Combining evaluation results..."
      echo -n "[" > $(results.evaluation-results.path)
      FIRST=true
      for json_file in /shared-data/eval_results/*.json; do
        if [ -f "$json_file" ]; then
          if [ "$FIRST" = false ]; then
            echo -n "," >> $(results.evaluation-results.path)
          fi
          cat "$json_file" >> $(results.evaluation-results.path)
          FIRST=false
        fi
      done
      echo -n "]" >> $(results.evaluation-results.path)

      echo "Evaluation completed successfully"
    fi
- op: replace
  path: /spec/steps/6/script
  value: |
    #!/bin/bash
    set -e
    echo "=== STEP 7: UPLOAD TO GOOGLE DRIVE ==="

    # Skip if "all" is not present in EVALUATE_SPECIFIC_NODE
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    if ! echo ",$EVAL_NODES," | grep -q ",all,"; then
      echo "Skipping Google Drive upload in evaluation mode (EVALUATE_SPECIFIC_NODE=$EVAL_NODES)"
      exit 0
    fi

    # Check if we have required parameters
    if [ -z "$GDRIVE_FOLDER_ID" ]; then
      # Try ConfigMap environment variable
      if [ -n "$GDRIVE_FOLDER_ID_FROM_CM" ]; then
        GDRIVE_FOLDER_ID="$GDRIVE_FOLDER_ID_FROM_CM"
        echo "Using Google Drive folder ID from ConfigMap: $GDRIVE_FOLDER_ID"
      else
        echo "Skipping Google Drive upload - no folder ID available"
        echo "This is not an error - pipeline continues gracefully"
        exit 0
      fi
    else
      echo "Using Google Drive folder ID from parameter: $GDRIVE_FOLDER_ID"
    fi

    # Check service account
    if [ ! -f "$GOOGLE_APPLICATION_CREDENTIALS" ]; then
      echo "Skipping Google Drive upload - service account not available"
      echo "This is not an error - pipeline continues gracefully"
      exit 0
    fi

    # Check if output file exists
    EXCEL_FILE="/shared-data/output/sast_ai_output.xlsx"
    if [ ! -f "$EXCEL_FILE" ]; then
      echo "ERROR: Excel file not found at $EXCEL_FILE"
      echo "Available files in output directory:"
      ls -la /shared-data/output/ || echo "Output directory is empty or inaccessible"
      exit 1
    fi

    # Install required packages
    echo "Installing required packages..."
    apt-get update -qq >/dev/null 2>&1 && apt-get install -y -qq curl jq python3-pip python3-venv >/dev/null 2>&1

    # Create virtual environment
    python3 -m venv /tmp/venv >/dev/null 2>&1
    source /tmp/venv/bin/activate

    # Install Python packages
    pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib >/dev/null 2>&1
    echo "Dependencies installed successfully"

    # Set filename
    EXCEL_FILENAME="${PROJECT_NAME}-${PROJECT_VERSION}"
    if [ -z "$EXCEL_FILENAME" ] || [ "$EXCEL_FILENAME" = "-" ]; then
      EXCEL_FILENAME="sast_ai_output"
    fi

    echo "File to upload: $EXCEL_FILE"
    echo "Remote filename: $EXCEL_FILENAME"
    echo "Target folder ID: $GDRIVE_FOLDER_ID"

    echo "Executing Google Drive upload..."
    python /scripts/gdrive_upload.py "$EXCEL_FILE" "$EXCEL_FILENAME" "$GDRIVE_FOLDER_ID"

    if [ $? -eq 0 ]; then
      echo "=== Google Drive upload completed successfully! ==="
    else
      echo "=== Google Drive upload failed ==="
      exit 1
    fi
- op: replace
  path: /spec/steps/7/script
  value: |
    #!/bin/bash
    set -e
    echo "=== STEP 8: UPLOAD SARIF TO GCS BUCKET ==="

    # Skip if "all" is not present in EVALUATE_SPECIFIC_NODE
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    if ! echo ",$EVAL_NODES," | grep -q ",all,"; then
      echo "Skipping GCS upload in evaluation mode (EVALUATE_SPECIFIC_NODE=$EVAL_NODES)"
      exit 0
    fi

    # Check if we have required parameters
    if [ -z "$GCS_BUCKET_NAME" ]; then
      echo "Skipping GCS upload - no bucket name provided"
      exit 0
    fi

    # Check service account
    if [ ! -f "$GOOGLE_APPLICATION_CREDENTIALS" ]; then
      echo "Skipping GCS upload - service account not available"
      exit 0
    fi

    # Look for the SARIF file in output directory
    SARIF_FILE=$(find /shared-data/output -name "*.sarif" -type f 2>/dev/null | head -1)

    if [ -z "$SARIF_FILE" ]; then
      echo "ERROR: No SARIF file found in output directory"
      echo "Available files in output directory:"
      ls -la /shared-data/output/ || echo "Output directory is empty or inaccessible"
      exit 1
    fi

    echo "Found SARIF file: $SARIF_FILE"

    # Install required packages
    echo "Installing required packages..."
    apt-get update -qq >/dev/null 2>&1 && apt-get install -y -qq python3-pip python3-venv >/dev/null 2>&1

    # Create virtual environment
    python3 -m venv /tmp/venv >/dev/null 2>&1
    source /tmp/venv/bin/activate

    # Install Google Cloud Storage
    pip install --quiet google-cloud-storage >/dev/null 2>&1
    echo "Dependencies installed successfully"

    # Generate timestamp for folder organization
    TIMESTAMP=$(date -u +"%Y-%m-%dT%H-%M-%S")

    # Upload the SARIF file
    SCAN_FILENAME=$(basename "$SARIF_FILE")

    # Create organized path: sarif-reports/timestamp/scan_filename
    DESTINATION_PATH="sarif-reports/${TIMESTAMP}/${SCAN_FILENAME}"

    echo "Uploading: $SARIF_FILE"
    echo "Destination: gs://$GCS_BUCKET_NAME/$DESTINATION_PATH"

    if python /scripts/gcs_upload.py "$SARIF_FILE" "$GCS_BUCKET_NAME" "$DESTINATION_PATH"; then
      echo "✓ Successfully uploaded: $SCAN_FILENAME"
      echo "=== SARIF file uploaded to GCS successfully! ==="
    else
      echo "✗ Failed to upload: $SCAN_FILENAME"
      echo "=== SARIF upload failed, but pipeline continues ==="
      # Don't fail the pipeline for upload issues
    fi
- op: replace
  path: /spec/steps/8/script
  value: |
    #!/usr/bin/env sh
    echo "=== STEP 9: CLEANUP ==="

    # Skip if "all" is not present in EVALUATE_SPECIFIC_NODE
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    if ! echo ",$EVAL_NODES," | grep -q ",all,"; then
      echo "Skipping cleanup in evaluation mode (EVALUATE_SPECIFIC_NODE=$EVAL_NODES)"
      exit 0
    fi

    CLEANED_ITEMS=""

    # Remove source code directory
    if [ -d "/shared-data/source" ]; then
        rm -rf /shared-data/source/* >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS source-code"
    fi

    # Remove false positives file
    if [ -f "/shared-data/false-positives/ignore.err" ]; then
        rm -f /shared-data/false-positives/ignore.err >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS false-positives"
    fi

    # Clean up any temporary files in cache
    if [ -d "/cache-data/tmp" ]; then
        rm -rf /cache-data/tmp/* >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS temp-files"
    fi

    # Report what was cleaned
    if [ -n "$CLEANED_ITEMS" ]; then
        echo "Cleaned:$CLEANED_ITEMS"
    else
        echo "Nothing to clean"
    fi

    # Preserve output file
    if [ -f "/shared-data/output/sast_ai_output.xlsx" ]; then
        echo "Output file preserved"
    fi

    echo "Cleanup completed successfully"