# Evaluation Mode Patches for MLOps Overlay - Simplified
#
# This file patches the base Tekton task to support evaluation mode.
# Removes unnecessary validation, checks, and upload steps.
# Assumes XLSX files always come from DVC/S3/MinIO.
#
# EVALUATE_SPECIFIC_NODE can be:
# - "all" - runs normal SAST workflow
# - "filter" - runs only filter evaluation
# - "judge" - runs only judge evaluation
# - "summary" - runs only summary evaluation
# - "all,filter" - runs normal SAST workflow + filter evaluation
#
- op: add
  path: /spec/results/-
  value:
    name: filter-evaluation-results
    description: "JSON evaluation results from filter node"
- op: add
  path: /spec/results/-
  value:
    name: judge-evaluation-results
    description: "JSON evaluation results from judge node"
- op: add
  path: /spec/results/-
  value:
    name: summary-evaluation-results
    description: "JSON evaluation results from summary node"
- op: add
  path: /spec/results/-
  value:
    name: workflow-metrics
    description: "JSON containing workflow metrics (TP/FP/TN/FN, accuracy, precision, recall, F1)"
# Override SERVICE_ACCOUNT_JSON_PATH to prevent Google Sheets authentication attempts
# MLOps evaluation mode always uses XLSX files from DVC/S3/MinIO, never Google Sheets
- op: replace
  path: /spec/steps/5/env/16/value
  value: ""
- op: replace
  path: /spec/steps/5/image
  value: "$(params.CONTAINER_IMAGE)"
- op: replace
  path: /spec/steps/5/script
  value: |
    #!/usr/bin/env sh
    set -e
    echo "=== STEP 6: RUN SAST AI ANALYSIS OR EVALUATION ==="

    # Load the repo path from step 4
    if [ -f "/shared-data/env.txt" ]; then
      source /shared-data/env.txt
      export REPO_LOCAL_PATH
    else
      echo "Error: No environment file found from prepare-source step" >&2
      exit 1
    fi

    # Use the transformed report file path if available
    if [ -f "/shared-data/report-file-path.txt" ]; then
      TRANSFORMED_REPORT_PATH=$(cat /shared-data/report-file-path.txt)
      export INPUT_REPORT_FILE_PATH="$TRANSFORMED_REPORT_PATH"
      export HUMAN_VERIFIED_FILE_PATH="$TRANSFORMED_REPORT_PATH"
      echo "Using transformed report file path: $INPUT_REPORT_FILE_PATH"
      echo "Using transformed ground truth file path: $HUMAN_VERIFIED_FILE_PATH"
    else
      echo "Using original report file path: $INPUT_REPORT_FILE_PATH"
    fi

    # Create directories
    mkdir -p "/cache-data/tmp" "/shared-data/output"

    # Parse and normalize EVALUATE_SPECIFIC_NODE parameter
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    EVAL_NODES_NORMALIZED=$(echo "$EVAL_NODES" | tr '[:upper:]' '[:lower:]' | sed 's/ //g')
    echo "Evaluation nodes: $EVAL_NODES_NORMALIZED"

    # Check if full workflow should run
    if echo ",$EVAL_NODES_NORMALIZED," | grep -q ",all,"; then
      RUN_FULL_WORKFLOW=true
      echo "Mode: Individual evaluations + full workflow"
    else
      RUN_FULL_WORKFLOW=false
      echo "Mode: Individual evaluations only"
    fi

    # PHASE 1: Individual node evaluations
    mkdir -p /shared-data/eval_results

    # Parse comma-separated list and run each evaluation runner
    echo "$EVAL_NODES_NORMALIZED" | tr ',' '\n' | while read -r node; do
      node=$(echo "$node" | xargs)  # trim whitespace

      # Skip "all" - it's handled by full workflow in Phase 2
      [ "$node" = "all" ] && continue

      # Parse ground truth XLSX file if needed for this evaluation node
      if [ -f "/shared-data/report-file-path.txt" ]; then
        GROUND_TRUTH_PATH=$(cat /shared-data/report-file-path.txt)

        # Check if it's an XLSX file that needs parsing
        if [[ "$GROUND_TRUTH_PATH" =~ \.xlsx$ ]]; then
          mkdir -p /shared-data/evaluation_dataset
          NVR="${PROJECT_NAME}-${PROJECT_VERSION}"

          # Map node names to parser node types
          case "$node" in
            summary)
              PARSER_NODE_TYPE="summarize"
              ;;
            filter|judge)
              PARSER_NODE_TYPE="$node"
              ;;
            *)
              continue
              ;;
          esac

          # Parse XLSX to JSON
          python /app/evaluation/utils/parse_excel_to_json.py \
            --node-type "$PARSER_NODE_TYPE" \
            single \
            --excel-file "$GROUND_TRUTH_PATH" \
            --package-name "$NVR" \
            --output-file "/shared-data/evaluation_dataset/parsed_dataset.json"

          if [ $? -eq 0 ]; then
            export EVALUATION_DATASET_PATH="/shared-data/evaluation_dataset/parsed_dataset.json"
          else
            echo "Error: XLSX parsing failed for $node, results of eval flow for $node is not saved."
            exit 0
          fi
        fi
      fi

      case "$node" in
        filter)
          echo "Evaluating: filter"
          echo "Running: python -u /app/evaluation/runners/run_filter_evaluation.py"
          echo "EVALUATION_JSON_OUTPUT=/shared-data/eval_results/filter.json"
          echo "EVALUATION_DATASET_PATH=$EVALUATION_DATASET_PATH"
          echo "---START PYTHON OUTPUT---"
          EVALUATION_JSON_OUTPUT=/shared-data/eval_results/filter.json \
            python -u /app/evaluation/runners/run_filter_evaluation.py 2>&1
          EXIT_CODE=$?
          echo "---END PYTHON OUTPUT---"
          echo "Filter eval exit code: $EXIT_CODE"
          if [ $EXIT_CODE -ne 0 ]; then
            echo "WARNING: Filter evaluation failed with exit code $EXIT_CODE, continuing to next node"
          fi
          ;;
        summary)
          echo "Evaluating: summary"
          echo "Running: python -u /app/evaluation/runners/run_summarize_evaluation.py"
          echo "EVALUATION_JSON_OUTPUT=/shared-data/eval_results/summary.json"
          echo "EVALUATION_DATASET_PATH=$EVALUATION_DATASET_PATH"
          echo "---START PYTHON OUTPUT---"
          EVALUATION_JSON_OUTPUT=/shared-data/eval_results/summary.json \
            python -u /app/evaluation/runners/run_summarize_evaluation.py 2>&1
          EXIT_CODE=$?
          echo "---END PYTHON OUTPUT---"
          echo "Summary eval exit code: $EXIT_CODE"
          if [ $EXIT_CODE -ne 0 ]; then
            echo "WARNING: Summary evaluation failed with exit code $EXIT_CODE, continuing to next node"
          fi
          ;;
        judge)
          echo "Evaluating: judge"
          echo "Running: python -u /app/evaluation/runners/run_judge_llm_evaluation.py"
          echo "EVALUATION_JSON_OUTPUT=/shared-data/eval_results/judge.json"
          echo "EVALUATION_DATASET_PATH=$EVALUATION_DATASET_PATH"
          echo "---START PYTHON OUTPUT---"
          EVALUATION_JSON_OUTPUT=/shared-data/eval_results/judge.json \
            python -u /app/evaluation/runners/run_judge_llm_evaluation.py 2>&1
          EXIT_CODE=$?
          echo "---END PYTHON OUTPUT---"
          echo "Judge eval exit code: $EXIT_CODE"
          if [ $EXIT_CODE -ne 0 ]; then
            echo "WARNING: Judge evaluation failed with exit code $EXIT_CODE, continuing to next node"
          fi
          ;;
      esac
    done

    # PHASE 2: Run full workflow AFTER evaluations (if "all" was present)
    if [ "$RUN_FULL_WORKFLOW" = "true" ]; then
      echo "Running full SAST workflow..."
      export WORKFLOW_JSON_OUTPUT="/shared-data/output/workflow_metrics.json"
      echo "---START FULL WORKFLOW OUTPUT---"
      aiq run --config_file /app/src/sast_agent_workflow/configs/config.yml --input "sast_agent"
      EXIT_CODE=$?
      echo "---END FULL WORKFLOW OUTPUT---"
      echo "Full workflow exit code: $EXIT_CODE"

      # Validate workflow succeeded
      if [ $EXIT_CODE -ne 0 ]; then
        echo "Error: Full workflow failed with exit code $EXIT_CODE" >&2
        exit 1
      fi

      # Validate output file exists
      if [ ! -f "/shared-data/output/sast_ai_output.xlsx" ]; then
        echo "Error: Output file not found!" >&2
        exit 1
      fi

      echo "Full workflow completed successfully"
    else
      # Create empty workflow metrics when full workflow doesn't run
      echo "{}" > /shared-data/output/workflow_metrics.json
      echo "Skipped full workflow - evaluation mode only"
    fi

    # Write PART 1 of evaluation results (filter + judge)
    echo ""
    echo "=== Writing Evaluation Results (Part 1/3) ==="

    # Write filter evaluation if exists
    if [ -f "/shared-data/eval_results/filter.json" ]; then
      cat /shared-data/eval_results/filter.json > $(results.filter-evaluation-results.path)
      FILTER_SIZE=$(wc -c < $(results.filter-evaluation-results.path))
      echo "filter-evaluation-results: $FILTER_SIZE bytes"
    else
      echo "{}" > $(results.filter-evaluation-results.path)
      echo "filter-evaluation-results: {} (empty)"
    fi

    # Write judge evaluation if exists
    if [ -f "/shared-data/eval_results/judge.json" ]; then
      cat /shared-data/eval_results/judge.json > $(results.judge-evaluation-results.path)
      JUDGE_SIZE=$(wc -c < $(results.judge-evaluation-results.path))
      echo "judge-evaluation-results: $JUDGE_SIZE bytes"
    else
      echo "{}" > $(results.judge-evaluation-results.path)
      echo "judge-evaluation-results: {} (empty)"
    fi

    echo "Step 5 completed - filter and judge results written"
- op: replace
  path: /spec/steps/6/script
  value: |
    #!/usr/bin/env sh
    echo "=== STEP 7: WRITE EVALUATION RESULTS (Part 2/3) ==="

    # Write summary evaluation result
    if [ -f "/shared-data/eval_results/summary.json" ]; then
      cat /shared-data/eval_results/summary.json > $(results.summary-evaluation-results.path)
      SUMMARY_SIZE=$(wc -c < $(results.summary-evaluation-results.path))
      echo "summary-evaluation-results: $SUMMARY_SIZE bytes"
    else
      echo "{}" > $(results.summary-evaluation-results.path)
      echo "summary-evaluation-results: {} (empty)"
    fi

    echo "Step 6 completed - summary result written"
- op: replace
  path: /spec/steps/7/script
  value: |
    #!/usr/bin/env sh
    echo "=== STEP 8: WRITE EVALUATION RESULTS (Part 3/3) ==="

    # Load repo path for DVC commit hash
    if [ -f "/shared-data/env.txt" ]; then
      . /shared-data/env.txt
      export REPO_LOCAL_PATH
    fi

    # Write workflow metrics
    if [ -f "/shared-data/output/workflow_metrics.json" ]; then
      cat /shared-data/output/workflow_metrics.json > $(results.workflow-metrics.path)
      METRICS_SIZE=$(wc -c < $(results.workflow-metrics.path))
      echo "workflow-metrics: $METRICS_SIZE bytes"
    else
      echo "{}" > $(results.workflow-metrics.path)
      echo "workflow-metrics: {} (empty)"
    fi

    # Write DVC results
    echo -n "$(params.PROJECT_VERSION)" > $(results.dvc-data-version.path)

    # For git repos, extract commit hash; for SRPM/non-git, leave empty
    if [ -d "$REPO_LOCAL_PATH/.git" ]; then
      cd "$REPO_LOCAL_PATH" && git rev-parse HEAD > $(results.dvc-commit-hash.path) || echo -n "" > $(results.dvc-commit-hash.path)
    else
      echo -n "" > $(results.dvc-commit-hash.path)
    fi

    # Pipeline stage identifier
    echo -n "sast_ai_analysis" > $(results.dvc-pipeline-stage.path)

    echo "Step 7 completed - workflow-metrics and dvc results written"
- op: replace
  path: /spec/steps/8/script
  value: |
    #!/usr/bin/env sh
    echo "=== STEP 9: CLEANUP ==="

    # Skip if "all" is not present in EVALUATE_SPECIFIC_NODE
    EVAL_NODES="$(params.EVALUATE_SPECIFIC_NODE)"
    EVAL_NODES_NORMALIZED=$(echo "$EVAL_NODES" | tr '[:upper:]' '[:lower:]' | sed 's/ //g')
    if ! echo ",$EVAL_NODES_NORMALIZED," | grep -q ",all,"; then
      echo "Skipping cleanup in evaluation mode (EVALUATE_SPECIFIC_NODE=$EVAL_NODES)"
      exit 0
    fi

    CLEANED_ITEMS=""

    # Remove source code directory
    if [ -d "/shared-data/source" ]; then
        rm -rf /shared-data/source/* >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS source-code"
    fi

    # Remove false positives file
    if [ -f "/shared-data/false-positives/ignore.err" ]; then
        rm -f /shared-data/false-positives/ignore.err >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS false-positives"
    fi

    # Clean up any temporary files in cache
    if [ -d "/cache-data/tmp" ]; then
        rm -rf /cache-data/tmp/* >/dev/null 2>&1
        CLEANED_ITEMS="$CLEANED_ITEMS temp-files"
    fi

    # Report what was cleaned
    if [ -n "$CLEANED_ITEMS" ]; then
        echo "Cleaned:$CLEANED_ITEMS"
    else
        echo "Nothing to clean"
    fi

    # Preserve output file
    if [ -f "/shared-data/output/sast_ai_output.xlsx" ]; then
        echo "Output file preserved"
    fi

    echo "Cleanup completed successfully"