- op: add
  path: /spec/params/-
  value:
    name: S3_OUTPUT_BUCKET_NAME
    type: string
    description: "S3/Minio bucket name for uploading analysis results"
    default: ""
- op: add
  path: /spec/params/-
  value:
    name: PIPELINE_RUN_ID
    type: string
    description: "Unique PipelineRun ID for S3 object key"
    default: ""
- op: add
  path: /spec/volumes/-
  value:
    name: s3-output-scripts
    configMap:
      name: s3-output-upload-scripts
      defaultMode: 0755
- op: replace
  path: /spec/steps/6
  value:
    name: upload-to-s3-output
    image: $(params.BASE_IMAGE)
    env:
      - name: EVALUATE_SPECIFIC_NODE
        value: "$(params.EVALUATE_SPECIFIC_NODE)"
      - name: S3_OUTPUT_BUCKET_NAME
        value: "$(params.S3_OUTPUT_BUCKET_NAME)"
      - name: PIPELINE_RUN_ID
        value: "$(params.PIPELINE_RUN_ID)"
      - name: PROJECT_NAME
        value: "$(params.PROJECT_NAME)"
      - name: PROJECT_VERSION
        value: "$(params.PROJECT_VERSION)"
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: sast-ai-s3-output-credentials
            key: access_key_id
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: sast-ai-s3-output-credentials
            key: secret_access_key
      - name: S3_ENDPOINT_URL
        valueFrom:
          secretKeyRef:
            name: sast-ai-s3-output-credentials
            key: endpoint_url
            optional: true
    volumeMounts:
      - name: shared-data
        mountPath: /shared-data
      - name: s3-output-scripts
        mountPath: /scripts/s3-output
    command: ["/scripts/upload_to_s3_output.sh"]