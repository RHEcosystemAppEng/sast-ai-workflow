- op: replace
  path: /spec/steps/3
  value:
    name: transform-report
    image: $(params.INFRASTRUCTURE_IMAGE)
    volumeMounts:
      - name: shared-data
        mountPath: /shared-data
    env:
      - name: INPUT_REPORT_FILE_PATH
        value: "$(params.INPUT_REPORT_FILE_PATH)"
      - name: DVC_REPO_URL
        value: "$(params.DVC_REPO_URL)"
      - name: DVC_DATA_VERSION
        value: "$(params.DVC_DATA_VERSION)"
      - name: S3_ENDPOINT_URL
        value: "$(params.S3_ENDPOINT_URL)"
      - name: S3_INPUT_BUCKET_NAME
        value: "$(params.S3_INPUT_BUCKET_NAME)"
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: sast-ai-s3-input-creds
            key: aws_access_key_id
            optional: true
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: sast-ai-s3-input-creds
            key: aws_secret_access_key
            optional: true
    script: |
      #!/bin/bash
      set -e
      echo "=== STEP 4: FETCH REPORT FILE FROM DVC ==="

      REPORT_PATH="$INPUT_REPORT_FILE_PATH"
      WORKSPACE_PATH="/shared-data"

      echo "Report path: $REPORT_PATH"
      echo "Workspace: $WORKSPACE_PATH"

      # Inline S3 validation using curl for reliability
      echo "Validating S3 endpoint configuration..."
      S3_AVAILABLE="true"

      if [ -z "$S3_ENDPOINT_URL" ]; then
        echo "Warning: S3_ENDPOINT_URL is not set"
        S3_AVAILABLE="false"
      else
        echo "S3 Endpoint: $S3_ENDPOINT_URL"
        echo "Testing connectivity to S3 endpoint with curl..."

        # Test S3 endpoint connectivity (ignoring HTTP errors, just checking if reachable)
        # S3/MinIO may return 403 without auth, which is fine - we just need to know it's there
        if curl -s --connect-timeout 10 --max-time 15 -o /dev/null -w "%{http_code}" "$S3_ENDPOINT_URL" | grep -qE "^(200|403|404)"; then
          echo "S3 endpoint is reachable"
        else
          echo "Warning: Cannot connect to S3 endpoint $S3_ENDPOINT_URL"
          S3_AVAILABLE="false"
        fi
      fi

      echo "$S3_AVAILABLE" > /shared-data/s3-available.txt
      echo "S3 availability status: $S3_AVAILABLE"

      if [ "$S3_AVAILABLE" = "false" ]; then
        echo "ERROR: S3 endpoint not available - cannot fetch evaluation data"
        echo "All evaluation steps will be skipped"
        echo "Please verify S3_ENDPOINT_URL configuration and network connectivity"
        exit 0
      fi

      # Extract the DVC path from the MinIO URL
      DVC_PATH=$(echo "$REPORT_PATH" | sed -n "s|.*/$S3_INPUT_BUCKET_NAME/\(.*\)|\1|p" | tr '[:upper:]' '[:lower:]' | sed 's/%20/ /g')

      if [ -z "$DVC_PATH" ]; then
        echo "Error: Could not extract DVC path from URL: $REPORT_PATH"
        exit 1
      fi

      echo "DVC Repository: $DVC_REPO_URL"
      echo "DVC Path: $DVC_PATH"
      echo "DVC Version: $DVC_DATA_VERSION"
      echo "S3 Endpoint: $S3_ENDPOINT_URL"

      # Extract file extension
      FILE_EXT="${DVC_PATH##*.}"
      echo "File extension: $FILE_EXT"

      # Use DVC to fetch the file
      DOWNLOADED_FILE="$WORKSPACE_PATH/downloaded_report.$FILE_EXT"
      dvc get "$DVC_REPO_URL" "${DVC_PATH}" --rev "$DVC_DATA_VERSION" -o "$DOWNLOADED_FILE" \
        || (echo "Error: Could not fetch report file from DVC/S3/MinIO" && exit 1)

      echo "Report file downloaded successfully via DVC"
      echo "File size: $(du -h $DOWNLOADED_FILE | cut -f1)"

      # Write result paths
      echo -n "$DOWNLOADED_FILE" > $(results.report-file-path.path)
      echo -n "$DOWNLOADED_FILE" > /shared-data/report-file-path.txt
      echo "Report saved as: $DOWNLOADED_FILE"

      echo "Report fetch completed"